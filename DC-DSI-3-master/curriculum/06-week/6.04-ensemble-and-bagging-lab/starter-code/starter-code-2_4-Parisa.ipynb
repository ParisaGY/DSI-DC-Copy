{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees and Ensembles Lab\n",
    "\n",
    "In this lab we will compare the performance of a simple Decision Tree classifier with a Bagging classifier. We will do that on few datasets, starting from the ones offered by Scikit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Breast Cancer Dataset\n",
    "We will start our comparison on the breast cancer dataset.\n",
    "You can load it directly from scikit-learn using the `load_breast_cancer` function.\n",
    "\n",
    "### 1.a Simple comparison\n",
    "1. Load the data and create X and y\n",
    "- Initialize a Decision Tree Classifier and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds\n",
    "- Wrap a Bagging Classifier around the Decision Tree Classifier and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds. \n",
    "- Which score is better? Are the score significantly different? How can you judge that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension           ...             worst radius  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "1                 0.05667           ...                    24.99   \n",
       "2                 0.05999           ...                    23.57   \n",
       "3                 0.09744           ...                    14.91   \n",
       "4                 0.05883           ...                    22.54   \n",
       "\n",
       "   worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0          17.33           184.60      2019.0            0.1622   \n",
       "1          23.41           158.80      1956.0            0.1238   \n",
       "2          25.53           152.50      1709.0            0.1444   \n",
       "3          26.50            98.87       567.7            0.2098   \n",
       "4          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#yy = data.target\n",
    "y = pd.DataFrame(data.target, columns=['benign'])\n",
    "y=data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972027972028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# STEP 1: split X and y into training and testing sets (using random_state for reproducibility)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99)\n",
    "\n",
    "# STEP 2: train the model on the training set (using K=1)\n",
    "logreg_cv = LogisticRegressionCV(solver='liblinear', cv = 5,penalty = 'l2')\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "# STEP 3: test the model on the testing set, and check the accuracy\n",
    "y_pred_class = logreg_cv.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree1= DecisionTreeClassifier(max_depth=1)\n",
    "dtree1.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score:\t0.910411696806\n",
      "Bagging Score:\t0.964971142747\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "Tree = DecisionTreeClassifier()\n",
    "bagging = BaggingClassifier(base_estimator = Tree, max_samples=0.5, max_features=0.5)\n",
    "\n",
    "print \"CV Score:\\t\", cross_val_score(Tree, X, y, cv=5, n_jobs=-1).mean()\n",
    "print \"Bagging Score:\\t\", cross_val_score(bagging, X, y, cv=5, n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b Scaled pipelines\n",
    "As you may have noticed the features are not normalized. Do the score improve with normalization?\n",
    "By now you should be very familiar with pipelines and scaling, so:\n",
    "\n",
    "1. Create 2 pipelines, with a scaling preprocessing step and then either a decision tree or a bagging decision tree.\n",
    "- Which score is better? Are the score significantly different? How can you judge that?\n",
    "- Are the scores different from the non-scaled data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.84      0.88        44\n",
      "          1       0.93      0.97      0.95        99\n",
      "\n",
      "avg / total       0.93      0.93      0.93       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "quote_clf = Pipeline([('mms', MinMaxScaler()),\n",
    "                    ('Tree', DecisionTreeClassifier())])\n",
    "\n",
    "\n",
    "quote_fit = quote_clf.fit(X_train, y_train)\n",
    "quote_pred = quote_fit.predict(X_test)\n",
    "print classification_report(y_test, quote_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c Grid Search\n",
    "\n",
    "Grid search is a great way to improve the performance of a classifier. Let's explore the parameter space of both models and see if we can improve their performance.\n",
    "\n",
    "1. Initialize a GridSearchCV with 5-fold cross validation for the Decision Tree Classifier\n",
    "- search for few values of the parameters in order to improve the score of the classifier\n",
    "- Use the whole X, y dataset for your test\n",
    "- Check the best\\_score\\_ once you've trained it. Is it better than before?\n",
    "- How does the score of the Grid-searched DT compare with the score of the Bagging DT?\n",
    "- Initialize a GridSearchCV with 5-fold cross validation for the Bagging Decision Tree Classifier\n",
    "    - This can take a really long time.\n",
    "- Repeat the search\n",
    "    - Note that you'll have to change parameter names for the base_estimator\n",
    "    - Note that there are also additional parameters to change\n",
    "    - Note that you may end up with a grid space to large to search in a short time\n",
    "    - Make use of the n_jobs parameter to speed up your grid search\n",
    "- Does the score improve for the Grid-searched Bagging Classifier?\n",
    "- Which score is better? Are the score significantly different? How can you judge that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'criterion': ['entropy', 'gini'], 'max_depth': [1, 2, 3, 4, 5, 6]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n",
      "0.93848857645\n",
      "4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.84      0.88        44\n",
      "          1       0.93      0.97      0.95        99\n",
      "\n",
      "avg / total       0.93      0.93      0.93       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run gridsearch using GridSearchCV and 5 folds\n",
    "# score on accuracy; what does this metric tell us?\n",
    "criteria = ['entropy','gini']\n",
    "max_vals = [1,2,3,4,5,6]\n",
    "Tree = DecisionTreeClassifier()\n",
    "\n",
    "#W.\n",
    "\n",
    "grid = GridSearchCV(estimator=Tree, param_grid=dict(max_depth=max_vals,criterion = criteria), cv=5)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "# find the best parameters of our gridsearch model.\n",
    "grid.best_params_\n",
    "print(grid)\n",
    "## Summarize the Results of the Grid Search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.max_depth)\n",
    "print classification_report(y_test, quote_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, ...n_estimators=10, n_jobs=1, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'max_features': [1, 2, 3], 'max_samples': [1, 2, 3]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n",
      "0.806678383128\n",
      "3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.84      0.88        44\n",
      "          1       0.93      0.97      0.95        99\n",
      "\n",
      "avg / total       0.93      0.93      0.93       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# run gridsearch using GridSearchCV and 5 folds\n",
    "# score on accuracy; what does this metric tell us?\n",
    "max_f= [1,2,3]\n",
    "max_vals = [1,2,3]\n",
    "cr = ['entropy','gini']\n",
    "bagging = BaggingClassifier(base_estimator = Tree)\n",
    "\n",
    "#W.\n",
    "\n",
    "grid = GridSearchCV(estimator=bagging, param_grid=dict(max_samples=max_vals,max_features = max_f), cv=5)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "# find the best parameters of our gridsearch model.\n",
    "grid.best_params_\n",
    "print(grid)\n",
    "## Summarize the Results of the Grid Search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.max_samples)\n",
    "print classification_report(y_test, quote_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Diabetes and Regression\n",
    "\n",
    "Scikit Learn has a dataset of diabetic patients obtained from this study:\n",
    "\n",
    "http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
    "http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf\n",
    "\n",
    "442 diabetes patients were measured on 10 baseline variables: age, sex, body mass index, average blood pressure, and six blood serum measurements.\n",
    "\n",
    "The target is a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "Repeat the above comparison between a DecisionTreeRegressor and a Bagging version of the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a Simple comparison\n",
    "1. Load the data and create X and y\n",
    "- Initialize a Decision Tree Regressor and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds. Which score will you use?\n",
    "- Wrap a Bagging Regressor around the Decision Tree Regressor and use cross_val_score to evaluate it's performance. Set crossvalidation to 5-folds. \n",
    "- Which score is better? Are the score significantly different? How can you judge that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>map</th>\n",
       "      <th>tc</th>\n",
       "      <th>ldl</th>\n",
       "      <th>hdl</th>\n",
       "      <th>tch</th>\n",
       "      <th>ltg</th>\n",
       "      <th>glu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi       map        tc       ldl       hdl  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "        tch       ltg       glu  \n",
       "0 -0.002592  0.019908 -0.017646  \n",
       "1 -0.039493 -0.068330 -0.092204  \n",
       "2 -0.002592  0.002864 -0.025930  \n",
       "3  0.034309  0.022692 -0.009362  \n",
       "4 -0.002592 -0.031991 -0.046641  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes \n",
    "data = load_diabetes()\n",
    "X = pd.DataFrame(data.data, columns= ['age', 'sex', 'bmi', 'map' ,'tc' ,'ldl' ,'hdl', 'tch' ,'ltg' ,'glu'])\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#yy = data.target\n",
    "y = pd.DataFrame(data.target, columns=['Diabetic'])\n",
    "y=data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegressionCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# STEP 1: split X and y into training and testing sets (using random_state for reproducibility)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=99)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Score:\t0.0216524703807\n"
     ]
    }
   ],
   "source": [
    "dtree1= DecisionTreeRegressor()\n",
    "dtree1.fit(X_train, y_train)\n",
    "print \"Tree Score:\\t\", cross_val_score(dtree1, X_train, y_train, cv=5, n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree Score:\t0.0216524703807\n",
      "Bagging Score:\t0.383585324604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "\n",
    "Tree = DecisionTreeRegressor()\n",
    "bagging = BaggingRegressor(base_estimator = Tree, max_samples=0.5, max_features=0.5)\n",
    "\n",
    "print \"tree Score:\\t\", cross_val_score(Tree, X_train, y_train, cv=5, n_jobs=-1).mean()\n",
    "print \"Bagging Score:\\t\", cross_val_score(bagging, X_train, y_train, cv=5, n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "           splitter='best'),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'max_features': [1, 2, 3, 4, 5], 'criterion': ['mse'], 'max_depth': [1, 2, 3, 4, 5, 6]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n",
      "0.353553284801\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# run gridsearch using GridSearchCV and 5 folds\n",
    "# score on accuracy; what does this metric tell us?\n",
    "criteria = ['mse']\n",
    "max_vals = [1,2,3,4,5,6]\n",
    "Tree = DecisionTreeRegressor()\n",
    "max_features = [1,2,3,4,5]\n",
    "#W.\n",
    "\n",
    "grid = GridSearchCV(estimator=Tree, param_grid=dict(max_depth=max_vals,criterion = criteria,max_features=max_features), cv=5)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "# find the best parameters of our gridsearch model.\n",
    "grid.best_params_\n",
    "print(grid)\n",
    "## Summarize the Results of the Grid Search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.max_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=BaggingRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "           splitter='best'),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'max_features': [1, 2, 3, 4, 5], 'max_samples': [1, 2, 3, 4, 5, 6]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n",
      "0.272594942743\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# run gridsearch using GridSearchCV and 5 folds\n",
    "# score on accuracy; what does this metric tell us?\n",
    "\n",
    "criteria = ['mse']\n",
    "max_vals = [1,2,3,4,5,6]\n",
    "Tree = DecisionTreeRegressor()\n",
    "max_features = [1,2,3,4,5]\n",
    "\n",
    "\n",
    "bagging = BaggingRegressor(base_estimator = Tree)\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=bagging, param_grid=dict(max_samples=max_vals,max_features = max_features), cv=5)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "# find the best parameters of our gridsearch model.\n",
    "grid.best_params_\n",
    "print(grid)\n",
    "## Summarize the Results of the Grid Search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.max_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b Grid Search\n",
    "\n",
    "Repeat Grid search as above:\n",
    "\n",
    "1. Initialize a GridSearchCV with 5-fold cross validation for the Decision Tree Regressor\n",
    "- Search for few values of the parameters in order to improve the score of the regressor\n",
    "- Use the whole X, y dataset for your test\n",
    "- Check the best\\_score\\_ once you've trained it. Is it better than before?\n",
    "- How does the score of the Grid-searched DT compare with the score of the Bagging DT?\n",
    "- Initialize a GridSearchCV with 5-fold cross validation for the Bagging Decision Tree Regressor\n",
    "- Repeat the search\n",
    "    - Note that you'll have to change parameter names for the base_estimator\n",
    "    - Note that there are also additional parameters to change\n",
    "    - Note that you may end up with a grid space to large to search in a short time\n",
    "    - Make use of the n_jobs parameter to speed up your grid search\n",
    "- Does the score improve for the Grid-searched Bagging Regressor?\n",
    "- Which score is better? Are the score significantly different? How can you judge that?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
