{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison Lab\n",
    "\n",
    "In this lab we will compare the performance of all the models we have learned about so far, using the car evaluation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the data\n",
    "\n",
    "The [car evaluation dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/car/) is in the assets/datasets folder. By now you should be very familiar with this dataset.\n",
    "\n",
    "1. Load the data into a pandas dataframe\n",
    "- Encode the categorical features properly: define a map that preserves the scale (assigning smaller numbers to words indicating smaller quantities)\n",
    "- Separate features from target into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>acceptability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety acceptability\n",
       "0  vhigh  vhigh     2       2    small    low         unacc\n",
       "1  vhigh  vhigh     2       2    small    med         unacc\n",
       "2  vhigh  vhigh     2       2    small   high         unacc\n",
       "3  vhigh  vhigh     2       2      med    low         unacc\n",
       "4  vhigh  vhigh     2       2      med    med         unacc"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/generalassembly/Documents/repo-DC-DSI-3/DC-DSI-3/curriculum/06-week/6.05-random-forests/assets/datasets/car.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying           False\n",
       "maint            False\n",
       "doors            False\n",
       "persons          False\n",
       "lug_boot         False\n",
       "safety           False\n",
       "acceptability    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_high</th>\n",
       "      <th>buying_low</th>\n",
       "      <th>buying_med</th>\n",
       "      <th>buying_vhigh</th>\n",
       "      <th>maint_high</th>\n",
       "      <th>maint_low</th>\n",
       "      <th>maint_med</th>\n",
       "      <th>maint_vhigh</th>\n",
       "      <th>doors_2</th>\n",
       "      <th>doors_3</th>\n",
       "      <th>...</th>\n",
       "      <th>doors_5more</th>\n",
       "      <th>persons_2</th>\n",
       "      <th>persons_4</th>\n",
       "      <th>persons_more</th>\n",
       "      <th>lug_boot_big</th>\n",
       "      <th>lug_boot_med</th>\n",
       "      <th>lug_boot_small</th>\n",
       "      <th>safety_high</th>\n",
       "      <th>safety_low</th>\n",
       "      <th>safety_med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying_high  buying_low  buying_med  buying_vhigh  maint_high  maint_low  \\\n",
       "0          0.0         0.0         0.0           1.0         0.0        0.0   \n",
       "1          0.0         0.0         0.0           1.0         0.0        0.0   \n",
       "2          0.0         0.0         0.0           1.0         0.0        0.0   \n",
       "3          0.0         0.0         0.0           1.0         0.0        0.0   \n",
       "4          0.0         0.0         0.0           1.0         0.0        0.0   \n",
       "\n",
       "   maint_med  maint_vhigh  doors_2  doors_3     ...      doors_5more  \\\n",
       "0        0.0          1.0      1.0      0.0     ...              0.0   \n",
       "1        0.0          1.0      1.0      0.0     ...              0.0   \n",
       "2        0.0          1.0      1.0      0.0     ...              0.0   \n",
       "3        0.0          1.0      1.0      0.0     ...              0.0   \n",
       "4        0.0          1.0      1.0      0.0     ...              0.0   \n",
       "\n",
       "   persons_2  persons_4  persons_more  lug_boot_big  lug_boot_med  \\\n",
       "0        1.0        0.0           0.0           0.0           0.0   \n",
       "1        1.0        0.0           0.0           0.0           0.0   \n",
       "2        1.0        0.0           0.0           0.0           0.0   \n",
       "3        1.0        0.0           0.0           0.0           1.0   \n",
       "4        1.0        0.0           0.0           0.0           1.0   \n",
       "\n",
       "   lug_boot_small  safety_high  safety_low  safety_med  \n",
       "0             1.0          0.0         1.0         0.0  \n",
       "1             1.0          0.0         0.0         1.0  \n",
       "2             1.0          1.0         0.0         0.0  \n",
       "3             0.0          0.0         1.0         0.0  \n",
       "4             0.0          0.0         0.0         1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = LabelEncoder().fit_transform(df['acceptability'])\n",
    "X = pd.get_dummies(df.drop('acceptability', axis=1))\n",
    "\n",
    "X.head() # did it work?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 1, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Useful preparation\n",
    "\n",
    "Since we will compare several models, let's write a couple of helper functions.\n",
    "\n",
    "1. Separate X and y between a train and test set, using 30% test set, random state = 42\n",
    "    - make sure that the data is shuffled and stratified\n",
    "2. Define a function called `evaluate_model`, that trains the model on the train set, tests it on the test, calculates:\n",
    "    - accuracy score\n",
    "    - confusion matrix\n",
    "    - classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "# STEP 1: split X and y into training and testing sets (using random_state for reproducibility)\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, random_state=42,test_size =0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## print metrics.accuracy_score(y_test, y_pred_tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.a KNN\n",
    "\n",
    "Let's start with `KNeighborsClassifier`.\n",
    "\n",
    "1. Initialize a KNN model\n",
    "- Evaluate it's performance with the function you previously defined\n",
    "- Find the optimal value of K using grid search\n",
    "    - Be careful on how you perform the cross validation in the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_total = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_axis=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888246628131\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.78      0.79       118\n",
      "          1       0.56      0.47      0.51        19\n",
      "          2       0.93      0.97      0.95       358\n",
      "          3       0.92      0.50      0.65        24\n",
      "\n",
      "avg / total       0.89      0.89      0.88       519\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 92,   3,  23,   0],\n",
       "       [  7,   9,   2,   1],\n",
       "       [ 10,   0, 348,   0],\n",
       "       [  7,   4,   1,  12]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# make an instance of a KNeighborsClassifier object\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "score_knn = metrics.accuracy_score(y_test, y_pred_knn)\n",
    "print score_knn\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'n_neighbors': [1, 2, 5, 10, 15]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n",
      "0.725115740741\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "n_neighbors = [1,2,5,10,15]\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=knn, param_grid=dict(n_neighbors=n_neighbors), cv=5)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "# find the best parameters of our gridsearch model.\n",
    "grid.best_params_\n",
    "print(grid)\n",
    "## Summarize the Results of the Grid Search\n",
    "x=grid.best_score_\n",
    "print(x)\n",
    "print(grid.best_estimator_.n_neighbors)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.b Bagging + KNN\n",
    "\n",
    "Now that we have found the optimal K, let's wrap `KNeighborsClassifier` in a BaggingClassifier and see if the score improves.\n",
    "\n",
    "1. Wrap the KNN model in a Bagging Classifier\n",
    "- Evaluate performance\n",
    "- Do a grid search only on the bagging classifier params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.894026974952\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.78      0.79       118\n",
      "          1       0.47      0.37      0.41        19\n",
      "          2       0.94      0.98      0.96       358\n",
      "          3       0.87      0.54      0.67        24\n",
      "\n",
      "avg / total       0.89      0.89      0.89       519\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 92,   5,  20,   1],\n",
       "       [ 10,   7,   1,   1],\n",
       "       [  6,   0, 352,   0],\n",
       "       [  8,   3,   0,  13]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "bagging = BaggingClassifier(base_estimator = knn)\n",
    "\n",
    "bagging.fit(X_train,y_train)\n",
    "y_pred_bagging = bagging.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, y_pred_bagging)\n",
    "print(classification_report(y_test, y_pred_bagging))\n",
    "confusion_matrix(y_test, y_pred_bagging)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10,...n_estimators=10, n_jobs=1, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'max_features': [1, 2, 3], 'max_samples': [10, 20, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "max_f= [1,2,3]\n",
    "max_vals = [10,20,30]\n",
    "grid = GridSearchCV(estimator=bagging, param_grid=dict(max_samples=max_vals,max_features = max_f), cv=5)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "# find the best parameters of our gridsearch model.\n",
    "grid.best_params_\n",
    "grid.best_score_\n",
    "print(grid)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression\n",
    "\n",
    "Let's see if logistic regression performs better\n",
    "\n",
    "1. Initialize LR and test on Train/Test set\n",
    "- Find optimal params with Grid Search\n",
    "- See if Bagging improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.870905587669\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.81      0.74       118\n",
      "          1       0.36      0.21      0.27        19\n",
      "          2       0.95      0.97      0.96       358\n",
      "          3       1.00      0.25      0.40        24\n",
      "\n",
      "avg / total       0.87      0.87      0.86       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# make an instance of a KNeighborsClassifier object\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "y_pred_lg = logreg.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, y_pred_lg)\n",
    "print(classification_report(y_test, y_pred_lg))\n",
    "confusion_matrix(y_test, y_pred_lg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'penalty': ['l1', 'l2'], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "Cs= [1,2,3,4,5,6,7,8,9]\n",
    "penalty= ['l1','l2']\n",
    "grid = GridSearchCV(estimator=logreg, param_grid=dict(C=Cs,penalty=penalty))\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "# find the best parameters of our gridsearch model.\n",
    "grid.best_params_\n",
    "print(grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['warm_start',\n",
       " 'C',\n",
       " 'n_jobs',\n",
       " 'verbose',\n",
       " 'intercept_scaling',\n",
       " 'fit_intercept',\n",
       " 'max_iter',\n",
       " 'penalty',\n",
       " 'multi_class',\n",
       " 'random_state',\n",
       " 'dual',\n",
       " 'tol',\n",
       " 'solver',\n",
       " 'class_weight']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.get_params().keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.863198458574\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.81      0.73       118\n",
      "          1       0.22      0.11      0.14        19\n",
      "          2       0.95      0.97      0.96       358\n",
      "          3       1.00      0.12      0.22        24\n",
      "\n",
      "avg / total       0.86      0.86      0.85       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging = BaggingClassifier(base_estimator = logreg)\n",
    "\n",
    "bagging.fit(X_train,y_train)\n",
    "y_pred_bagging = bagging.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, y_pred_bagging)\n",
    "print(classification_report(y_test, y_pred_bagging))\n",
    "confusion_matrix(y_test, y_pred_bagging)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Decision Trees\n",
    "\n",
    "Let's see if Decision Trees perform better\n",
    "\n",
    "1. Initialize DT and test on Train/Test set\n",
    "- Find optimal params with Grid Search\n",
    "- See if Bagging improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957610789981\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.89      0.92       118\n",
      "          1       0.71      0.89      0.79        19\n",
      "          2       0.99      0.99      0.99       358\n",
      "          3       0.83      0.79      0.81        24\n",
      "\n",
      "avg / total       0.96      0.96      0.96       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# make an instance of a KNeighborsClassifier object\n",
    "dtree= DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)\n",
    "y_pred_dtree = dtree.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, y_pred_dtree)\n",
    "print(classification_report(y_test, y_pred_dtree))\n",
    "confusion_matrix(y_test, y_pred_dtree)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'max_features': [0.5, 0.7, 0.9], 'criterion': ['entropy', 'gini'], 'max_depth': [0.5, 0.7, 0.9]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "criterion= ['entropy','gini']\n",
    "max_features=[0.5,0.7,0.9]\n",
    "max_depth =[0.5,0.7,0.9]\n",
    "grid = GridSearchCV(estimator=dtree, param_grid=dict(criterion=criterion,max_depth =max_depth,max_features=max_features ))\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "# find the best parameters of our gridsearch model.\n",
    "grid.best_params_\n",
    "print(grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953757225434\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91       118\n",
      "          1       0.68      0.89      0.77        19\n",
      "          2       0.99      0.98      0.99       358\n",
      "          3       0.83      0.79      0.81        24\n",
      "\n",
      "avg / total       0.96      0.95      0.95       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging = BaggingClassifier(base_estimator = dtree)\n",
    "\n",
    "bagging.fit(X_train,y_train)\n",
    "y_pred_bagging = bagging.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, y_pred_bagging)\n",
    "print(classification_report(y_test, y_pred_bagging))\n",
    "confusion_matrix(y_test, y_pred_bagging)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, ...n_estimators=10, n_jobs=1, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'max_features': [1, 2, 3], 'max_samples': [10, 20, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "max_f= [1,2,3]\n",
    "max_vals = [10,20,30]\n",
    "grid = GridSearchCV(estimator=bagging, param_grid=dict(max_samples=max_vals,max_features = max_f), cv=5)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "# find the best parameters of our gridsearch model.\n",
    "grid.best_params_\n",
    "print(grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Random Forest & Extra Trees\n",
    "\n",
    "Let's see if Random Forest and Extra Trees perform better\n",
    "\n",
    "1. Initialize RF and ET and test on Train/Test set\n",
    "- Find optimal params with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.924855491329\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.90      0.87       118\n",
      "          1       0.55      0.84      0.67        19\n",
      "          2       0.99      0.97      0.98       358\n",
      "          3       0.91      0.42      0.57        24\n",
      "\n",
      "avg / total       0.93      0.92      0.92       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "\n",
    "# make an instance of a KNeighborsClassifier object\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, y_pred_rf)\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'max_features': [0.5, 0.7, 0.9], 'criterion': ['entropy', 'gini'], 'max_depth': [0.5, 0.7, 0.9]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "criterion= ['entropy','gini']\n",
    "max_features=[0.5,0.7,0.9]\n",
    "max_depth =[0.5,0.7,0.9]\n",
    "grid = GridSearchCV(estimator=rf, param_grid=dict(criterion=criterion,max_depth =max_depth,max_features=max_features ))\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "# find the best parameters of our gridsearch model.\n",
    "grid.best_params_\n",
    "print(grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.946050096339\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.92      0.89       118\n",
      "          1       0.72      0.68      0.70        19\n",
      "          2       0.98      0.99      0.99       358\n",
      "          3       0.94      0.67      0.78        24\n",
      "\n",
      "avg / total       0.95      0.95      0.94       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging = BaggingClassifier(base_estimator = rf)\n",
    "\n",
    "bagging.fit(X_train,y_train)\n",
    "y_pred_bagging = bagging.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, y_pred_bagging)\n",
    "print(classification_report(y_test, y_pred_bagging))\n",
    "confusion_matrix(y_test, y_pred_bagging)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10,...n_estimators=10, n_jobs=1, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'max_features': [1, 2, 3], 'max_samples': [10, 20, 30]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "max_f= [1,2,3]\n",
    "max_vals = [10,20,30]\n",
    "grid = GridSearchCV(estimator=bagging, param_grid=dict(max_samples=max_vals,max_features = max_f), cv=5)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "# find the best parameters of our gridsearch model.\n",
    "grid.best_params_\n",
    "print(grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961464354528\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.92      0.93       118\n",
      "          1       0.71      0.89      0.79        19\n",
      "          2       0.99      0.99      0.99       358\n",
      "          3       0.86      0.79      0.83        24\n",
      "\n",
      "avg / total       0.96      0.96      0.96       519\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[109,   5,   2,   2],\n",
       "       [  1,  17,   0,   1],\n",
       "       [  4,   0, 354,   0],\n",
       "       [  3,   2,   0,  19]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "\n",
    "# make an instance of a KNeighborsClassifier object\n",
    "et = ExtraTreesClassifier(n_jobs=-1)\n",
    "et.fit(X_train,y_train)\n",
    "y_pred_et = et.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, y_pred_et)\n",
    "print(classification_report(y_test, y_pred_et))\n",
    "confusion_matrix(y_test, y_pred_et)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model comparison\n",
    "\n",
    "Let's compare the scores of the various models.\n",
    "\n",
    "1. Do a bar chart of the scores of the best models. Who's the winner on the train/test split?\n",
    "- Re-test all the models using a 3 fold stratified shuffled cross validation\n",
    "- Do a bar chart with errorbars of the cross validation average scores. is the winner the same?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_total=[0.888246628131,0.725115740741,0.894026974952,0.870905587669,0.867052023121,0.959537572254,\n",
    "             0.967244701349,0.924855491329,0.942196531792,0.961464354528]\n",
    "x_axis = ['knn','knn_gridsearch','knn_bagging','Logistic Regression','bagging_Logistic Regression','DecisionTrees',\n",
    "          'bagging_tree','Random Forest','bagging_rf','ExtraTreesClassifier']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.plot(kind='bar',);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "We have encoded the data using a map that preserves the scale.\n",
    "Would our results have changed if we had encoded the categorical data using `pd.get_dummies` or `OneHotEncoder`  to encode them as binary variables instead?\n",
    "\n",
    "1. Repeat the analysis for this scenario. Is it better?\n",
    "- Experiment with other models or other parameters; can you beat your classmates best score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
